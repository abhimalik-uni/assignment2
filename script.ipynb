{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "file_path = 'data/melb_data.csv'  # Replace with the actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the average number of sales per suburb\n",
    "average_sales_per_suburb = data.groupby('Suburb').size().mean()\n",
    "\n",
    "# Calculate the difference for each suburb\n",
    "sales_difference_per_suburb = data.groupby('Suburb').size() - average_sales_per_suburb\n",
    "\n",
    "# Create a new DataFrame to store the sales difference per suburb\n",
    "sales_difference_df = pd.DataFrame({\n",
    "    'Suburb': sales_difference_per_suburb.index,\n",
    "    'SalesDifference': sales_difference_per_suburb.values,\n",
    "    'NumberofSales': data.groupby('Suburb').size().values  # Add the number of sales\n",
    "})\n",
    "\n",
    "# Save the sales difference per suburb to a new CSV\n",
    "sales_difference_df.to_csv('sales_difference_per_suburb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.2484076433121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sales_per_suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 suburbs for 2016 saved to top_10_suburbs_2016.csv\n",
      "Top 10 suburbs for 2017 saved to top_10_suburbs_2017.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "# Initialize dictionaries to store the count of properties sold for each suburb in each year\n",
    "properties_by_year = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Read the CSV file\n",
    "with open('data/melb_data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Extract the year from the date\n",
    "        year = int(row['Date'].split('/')[-1])\n",
    "        \n",
    "        # Get the suburb\n",
    "        suburb = row['Suburb']\n",
    "        \n",
    "        # Update the count of properties sold for the respective year and suburb\n",
    "        properties_by_year[year][suburb] += 1\n",
    "\n",
    "# Sort the suburbs by the number of properties sold in each year\n",
    "sorted_properties_by_year = {year: dict(sorted(suburbs.items(), key=operator.itemgetter(1), reverse=True)) for year, suburbs in properties_by_year.items()}\n",
    "\n",
    "# Output the top 5 suburbs for each year into separate CSV files\n",
    "for year, suburbs in sorted_properties_by_year.items():\n",
    "    top_10_suburbs = dict(list(suburbs.items())[:10])\n",
    "    output_file = f'top_10_suburbs_{year}.csv'\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Suburb', 'Properties Sold'])\n",
    "        for suburb, count in top_10_suburbs.items():\n",
    "            writer.writerow([suburb, count])\n",
    "    print(f'Top 10 suburbs for {year} saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Price: 903000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('data/melb_data.csv')  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Calculate the median of the \"Price\" column\n",
    "median_price = df['Price'].median()\n",
    "\n",
    "print('Median Price:', median_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Median Price: 2185000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('data/suburb_medians.csv')  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Calculate the median of the \"Price\" column\n",
    "max_median_price = df['Median Price'].max()\n",
    "\n",
    "print('Max Median Price:', max_median_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed and saved to preprocessed_melb_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the CSV data\n",
    "url = \"https://raw.githubusercontent.com/abhimalik-uni/assignment2/main/data/melb_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Function to preprocess the date\n",
    "def preprocess_date(date_str):\n",
    "    try:\n",
    "        # Try parsing as \"dd/mm/yyyy\"\n",
    "        return datetime.strptime(date_str, \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try parsing as \"d/mm/yyyy\"\n",
    "            return datetime.strptime(date_str, \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "        except ValueError:\n",
    "            return None  # Return None for invalid dates\n",
    "\n",
    "# Preprocess the \"Date\" column\n",
    "data[\"Date\"] = data[\"Date\"].apply(preprocess_date)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "updated_csv_path = \"preprocessed_melb_data.csv\"\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Data preprocessed and saved to\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Suburb           Address  Rooms Type      Price Method SellerG  \\\n",
      "0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n",
      "1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
      "2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n",
      "3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n",
      "4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n",
      "\n",
      "         Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
      "0  03/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
      "1  04/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
      "2  04/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
      "3  04/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n",
      "4  04/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n",
      "\n",
      "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
      "0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
      "1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
      "2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n",
      "3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n",
      "4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n",
      "\n",
      "  Propertycount  \n",
      "0        4019.0  \n",
      "1        4019.0  \n",
      "2        4019.0  \n",
      "3        4019.0  \n",
      "4        4019.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed data\n",
    "preprocessed_data = pd.read_csv(\"data/preprocessed_melb_data.csv\")\n",
    "\n",
    "# Display the first few rows to verify the preprocessing\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed and saved to preprocessed_melb_data_month.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original data\n",
    "url = \"https://raw.githubusercontent.com/abhimalik-uni/assignment2/main/data/melb_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Function to preprocess the date and extract month\n",
    "def preprocess_date_and_extract_month(date_str):\n",
    "    try:\n",
    "        # Parse the date\n",
    "        parsed_date = pd.to_datetime(date_str, format=\"%d/%m/%Y\")\n",
    "        return parsed_date.month\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Preprocess the \"Date\" column and extract month\n",
    "data[\"Month\"] = data[\"Date\"].apply(preprocess_date_and_extract_month)\n",
    "\n",
    "# Drop rows with missing or invalid month\n",
    "data = data.dropna(subset=[\"Month\"])\n",
    "data[\"Month\"] = data[\"Month\"].astype(int)\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "updated_csv_path = \"preprocessed_melb_data_month.csv\"\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Data preprocessed and saved to\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with DayOfWeek column saved to data/preprocessed_melb_data_with_day.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the data\n",
    "url = \"data/preprocessed_melb_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Function to convert date to day of the week\n",
    "def convert_to_day_of_week(date_str):\n",
    "    try:\n",
    "        # Parse the date and get the day of the week\n",
    "        parsed_date = datetime.strptime(date_str, \"%d/%m/%Y\")\n",
    "        day_of_week = parsed_date.strftime(\"%A\")  # Full weekday name\n",
    "        return day_of_week\n",
    "    except ValueError:\n",
    "        return None  # Return None for invalid dates\n",
    "\n",
    "# Apply the function to the \"Date\" column\n",
    "data[\"DayOfWeek\"] = data[\"Date\"].apply(convert_to_day_of_week)\n",
    "\n",
    "# Save the updated data to a new CSV file with the \"DayOfWeek\" column\n",
    "updated_csv_path = \"data/preprocessed_melb_data_with_day.csv\"\n",
    "data.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "print(\"Data with DayOfWeek column saved to\", updated_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. JSON data saved to melb_data.json.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file, json_file):\n",
    "    data = []\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    with open(json_file, 'w', encoding='utf-8') as jsonfile:\n",
    "        jsonfile.write(json.dumps(data, indent=4))\n",
    "\n",
    "# Convert CSV to JSON\n",
    "csv_file_path = 'data/melb_data.csv'\n",
    "json_file_path = 'melb_data.json'\n",
    "csv_to_json(csv_file_path, json_file_path)\n",
    "\n",
    "print(f'Conversion completed. JSON data saved to {json_file_path}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. JSON data saved to melb_data.json.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def parse_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def csv_to_json(csv_file, json_file):\n",
    "    data = []\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            # Parse specified columns as floats\n",
    "            row['Rooms'] = parse_float(row['Rooms'])\n",
    "            row['Price'] = parse_float(row['Price'])\n",
    "            row['Distance'] = parse_float(row['Distance'])\n",
    "            row['Bedroom2'] = parse_float(row['Bedroom2'])\n",
    "            row['Bathroom'] = parse_float(row['Bathroom'])\n",
    "            row['Car'] = parse_float(row['Car'])\n",
    "            row['Landsize'] = parse_float(row['Landsize'])\n",
    "            row['Propertycount'] = parse_float(row['Propertycount'])\n",
    "            try:\n",
    "                row['YearBuilt'] = int(row['YearBuilt'])\n",
    "            except:\n",
    "                row['YearBuilt'] = 0\n",
    "            row['BuildingArea'] = parse_float(row['BuildingArea'])\n",
    "            data.append(row)\n",
    "    \n",
    "    with open(json_file, 'w', encoding='utf-8') as jsonfile:\n",
    "        jsonfile.write(json.dumps(data, indent=4))\n",
    "\n",
    "# Convert CSV to JSON\n",
    "csv_file_path = 'data/melb_data.csv'\n",
    "json_file_path = 'melb_data.json'\n",
    "csv_to_json(csv_file_path, json_file_path)\n",
    "\n",
    "print(f'Conversion completed. JSON data saved to {json_file_path}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to seller_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "url = \"https://raw.githubusercontent.com/abhimalik-uni/assignment2/main/data/melb_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Count the number of properties for each SellerG\n",
    "seller_counts = df['SellerG'].value_counts()\n",
    "\n",
    "# Replace sellers with count < 700 with \"Other\"\n",
    "df['SellerG'] = df['SellerG'].apply(lambda x: 'Other' if seller_counts[x] < 700 else x)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('seller_data.csv', index=False)\n",
    "\n",
    "# Print a message indicating successful save\n",
    "print('Updated data saved to seller_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved date counts for the year 2016 to data/date_counts_year.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the original CSV data\n",
    "data = pd.read_csv('data/preprocessed_melb_data.csv')\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Define the year for which you want to generate the date range\n",
    "target_year = 2016\n",
    "\n",
    "# Generate a date range for the specified year\n",
    "start_date = datetime(target_year, 1, 1)\n",
    "end_date = datetime(target_year, 12, 31)\n",
    "date_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "# Create a DataFrame with all possible dd/mm dates for the year\n",
    "all_dates_df = pd.DataFrame(date_range, columns=['Date'])\n",
    "all_dates_df['Date'] = all_dates_df['Date'].dt.strftime('%d/%m')\n",
    "\n",
    "# Count the occurrences for each date in the original data\n",
    "date_counts = data.groupby(data['Date'].dt.strftime('%d/%m')).size().reset_index(name='Count')\n",
    "\n",
    "# Merge to include zero counts for missing dates\n",
    "result_df = pd.merge(all_dates_df, date_counts, on='Date', how='left').fillna(0)\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('data/date_counts_year.csv', index=False)\n",
    "\n",
    "print(f'Saved date counts for the year {target_year} to data/date_counts_year.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: output_melb_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_path = 'data/melb_data.csv'  # Update with the correct file path\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Calculate properties sold per PropertyCount for each suburb\n",
    "data['PropertiesSoldPerPropertyCount'] = data.groupby('Suburb')['Propertycount'].transform('count') / data['Propertycount']\n",
    "\n",
    "# Calculate the average properties sold per PropertyCount for each suburb\n",
    "average_per_suburb = data.groupby('Suburb')['PropertiesSoldPerPropertyCount'].mean()\n",
    "\n",
    "# Calculate the overall average properties sold per PropertyCount\n",
    "overall_average = data['PropertiesSoldPerPropertyCount'].mean()\n",
    "\n",
    "# Calculate the sales difference for each suburb\n",
    "data['SalesDifference'] = average_per_suburb - overall_average\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_csv_path = 'output_melb_data.csv'  # Specify the desired output file path\n",
    "data[['Suburb', 'PropertiesSoldPerPropertyCount', 'SalesDifference']].to_csv(output_csv_path, index=False)\n",
    "\n",
    "print('Results saved to:', output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "csv_path = 'data/melb_data.csv'  # Update with the correct file path\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Count the number of properties sold for each suburb\n",
    "properties_sold_by_suburb = data['Suburb'].value_counts().reset_index()\n",
    "properties_sold_by_suburb.columns = ['Suburb', 'PropertiesSoldCount']\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_csv_path = 'properties_sold_by_suburb.csv'  # Specify the desired output file path\n",
    "properties_sold_by_suburb.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print('Results saved to:', output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: normalized_properties_sold_relative.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the input CSV into a DataFrame\n",
    "file_path = 'data/melb_data.csv'  # Replace with the actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the number of properties sold for each suburb\n",
    "properties_sold_per_suburb = data.groupby('Suburb').size()\n",
    "\n",
    "# Get the PropertyCount for each suburb\n",
    "property_count_per_suburb = data.groupby('Suburb')['Propertycount'].mean()\n",
    "\n",
    "# Calculate relative sales (NumberSold/PropertyCount) for each suburb\n",
    "relative_sales_per_suburb = properties_sold_per_suburb / property_count_per_suburb\n",
    "\n",
    "# Calculate the average relative sales across all suburbs\n",
    "global_average_relative_sales = relative_sales_per_suburb.mean()\n",
    "\n",
    "# Normalize the relative sales values to range from -1 to 1\n",
    "min_relative_sales = relative_sales_per_suburb.min()\n",
    "max_relative_sales = relative_sales_per_suburb.max()\n",
    "normalized_relative_sales = 2 * ((relative_sales_per_suburb - global_average_relative_sales) / (max_relative_sales - min_relative_sales))\n",
    "normalized_relative_sales = normalized_relative_sales.clip(-1, 1)\n",
    "\n",
    "# Create a DataFrame with the desired columns\n",
    "output_data = pd.DataFrame({\n",
    "    'Suburb': properties_sold_per_suburb.index,\n",
    "    'NumberSold': properties_sold_per_suburb.values,\n",
    "    'RelativeSales': normalized_relative_sales.values,\n",
    "    'GlobalAverage': [0] * len(properties_sold_per_suburb)  # Global average is now 0 after normalization\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a new CSV\n",
    "output_path = 'normalized_properties_sold_relative.csv'\n",
    "output_data.to_csv(output_path, index=False)\n",
    "\n",
    "print('Results saved to:', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('data/melb_data.csv')\n",
    "\n",
    "# Preprocessing to calculate median prices for each suburb based on specified criteria\n",
    "median_prices = df.groupby(['Suburb', 'Type', 'Bedroom2', 'Bathroom', 'Landsize'])['Price'].median().reset_index()\n",
    "\n",
    "# Save the preprocessed data to a new CSV\n",
    "median_prices.to_csv('median_prices.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. Updated CSV saved to melb_data_floats.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "csv_url = \"https://raw.githubusercontent.com/abhimalik-uni/assignment2/main/data/melb_data.csv\"\n",
    "\n",
    "# Columns to convert to floats\n",
    "columns_to_convert = ['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize',\n",
    "                      'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount']\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "# Convert specified columns to floats\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "\n",
    "# Output path for the updated CSV\n",
    "output_csv_path = \"melb_data_floats.csv\"\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"Conversion completed. Updated CSV saved to\", output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to: data/updated_normalized_properties_sold_relative.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "file_path = 'data/normalized_properties_sold_relative.csv'  # Replace with the actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Double all negative values in the RelativeSales column\n",
    "data['RelativeSales'] = data['RelativeSales'].apply(lambda x: x * 2 if x < 0 else x)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "updated_output_path = 'data/updated_normalized_properties_sold_relative.csv'\n",
    "data.to_csv(updated_output_path, index=False)\n",
    "\n",
    "print('Updated CSV saved to:', updated_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: data/suburb_median_prices.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the input CSV into a DataFrame\n",
    "file_path = 'data/melb_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the median price for each suburb\n",
    "median_price_per_suburb = data.groupby('Suburb')['Price'].median()\n",
    "\n",
    "# Get unique suburb and region name pairs\n",
    "suburb_region_mapping = data[['Suburb', 'Regionname']].drop_duplicates()\n",
    "\n",
    "# Merge the median prices with the suburb and region mapping\n",
    "result_data = suburb_region_mapping.merge(median_price_per_suburb, on='Suburb')\n",
    "\n",
    "# Rename columns\n",
    "result_data.rename(columns={'Price': 'MedianPrice'}, inplace=True)\n",
    "\n",
    "# Save the result to a new CSV\n",
    "output_path = 'data/suburb_median_prices.csv'\n",
    "result_data.to_csv(output_path, index=False)\n",
    "\n",
    "print('Results saved to:', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. CSV file with MonthName column saved at: melb_data_monthNames.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = 'preprocessed_melb_data_month.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define a mapping of month numbers to month names\n",
    "month_names = {\n",
    "    1: 'January',\n",
    "    2: 'February',\n",
    "    3: 'March',\n",
    "    4: 'April',\n",
    "    5: 'May',\n",
    "    6: 'June',\n",
    "    7: 'July',\n",
    "    8: 'August',\n",
    "    9: 'September',\n",
    "    10: 'October',\n",
    "    11: 'November',\n",
    "    12: 'December'\n",
    "}\n",
    "\n",
    "# Add a MonthName column based on the Month column\n",
    "df['MonthName'] = df['Month'].map(month_names)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "output_file_path = 'melb_data_monthNames.csv'  # Replace with the desired output path\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('Conversion completed. CSV file with MonthName column saved at:', output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total price for properties sold by specified sellers: 14607789799.0\n",
      "Number of unique sellerG: 268\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "data = pd.read_csv('data/melb_data.csv')\n",
    "\n",
    "# Extract the 'SellerG' column and find unique values\n",
    "unique_sellerG = data['SellerG'].nunique()\n",
    "\n",
    "specified_sellers = ['Barry', 'hockingstuart', 'Jellis', 'Nelson', 'Ray']\n",
    "\n",
    "# Filter the DataFrame based on specified sellers and calculate total price\n",
    "total_price = data['Price'].sum()\n",
    "\n",
    "print('Total price for properties sold by specified sellers:', total_price)\n",
    "\n",
    "print('Number of unique sellerG:', unique_sellerG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to: data/region_property_counts.csv\n",
      "Sum of property counts for each Regionname:\n",
      "                   Regionname  Propertycount\n",
      "0        Eastern Metropolitan       253713.0\n",
      "1            Eastern Victoria        77946.0\n",
      "2       Northern Metropolitan       343845.0\n",
      "3           Northern Victoria        39049.0\n",
      "4  South-Eastern Metropolitan       224843.0\n",
      "5       Southern Metropolitan       324889.0\n",
      "6        Western Metropolitan       302100.0\n",
      "7            Western Victoria        14311.0\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/melb_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group by suburb and extract unique property count and region name for each suburb\n",
    "suburb_info = df.groupby('Suburb').agg({\n",
    "    'Propertycount': 'max',  # Assuming property count is the same for all properties in a suburb, so we take the maximum\n",
    "    'Regionname': 'first'   # Assuming region name is the same for all properties in a suburb, so we take the first value\n",
    "}).reset_index()\n",
    "\n",
    "region_property_counts = suburb_info.groupby('Regionname')['Propertycount'].sum().reset_index()\n",
    "\n",
    "output_file_path = 'data/region_property_counts.csv'\n",
    "\n",
    "# Save the region_property_counts DataFrame to a CSV file\n",
    "region_property_counts.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Output saved to: {output_file_path}\")\n",
    "print(\"Sum of property counts for each Regionname:\")\n",
    "print(region_property_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
